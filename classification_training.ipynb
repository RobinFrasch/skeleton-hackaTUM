{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Binary Classification Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This Notebook contains the myDataset.py code and the training loop which were used to create the binary classification training.\n",
    "The model which was used is a derivation of the UNet implementation by https://github.com/milesial/Pytorch-UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Unet parts, classes that are needed for the network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        conv_layer1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        conv_layer2 = nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "\n",
    "        self.double_conv = nn.Sequential(\n",
    "            conv_layer1,# bias was false\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            conv_layer2,# bias was false\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "    def normal_init(m, mean, std):\n",
    "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "            m.weight.data.normal_(mean, std)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "UNet architecture with initialization and the forward pass. As is visible, the decoder part was omitted in favour of a smaller model that yields a single digit output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Basis was a standard UNet as proposed by Ronneberger, Fischer and Brox.\n",
    "To generate a single value decision, the decoder part was deleted in favour of a dense linear output layer, followed by a sigmoid function.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 3)\n",
    "        self.down1 = Down(3, 6)\n",
    "        self.down2 = Down(6, 12)\n",
    "        self.lin = torch.nn.Linear(12*120*160, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x3 = x3.flatten(start_dim=1)\n",
    "        logit = self.lin(x3)\n",
    "        return torch.nn.functional.sigmoid(logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The myDataset.py file is separated in myDataset_train and myDataset_val, as for the validation no data augmentation should be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class myDataset_train:\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(os.listdir(self.data_path))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        # image call\n",
    "        img = Image.open(os.path.join(self.data_path, 'img_{}.jpg'.format(i)))\n",
    "\n",
    "        # transformation to torch.Tensor\n",
    "        img_array = np.array(img)\n",
    "        img_tensor = torch.tensor(img_array)\n",
    "        img_tensor = torch.unsqueeze(img_tensor,0)\n",
    "        #\n",
    "        # # strong data augmentation to compensate for little training data\n",
    "        degrees = random.uniform(-10.0, 10.0)\n",
    "        translate_x = random.uniform(-1, 1)\n",
    "        translate_y = random.uniform(-1, 1)\n",
    "        scale = random.uniform(0.9, 1.1)\n",
    "\n",
    "        img_tensor = transforms.functional.affine(img=img_tensor, shear=0, angle=degrees, translate=(translate_x, translate_y), scale=scale, interpolation=transforms.InterpolationMode.BILINEAR, fill=0)\n",
    "\n",
    "        # ids of images with fractures\n",
    "        fractures = range(12)\n",
    "\n",
    "        # creation of target value\n",
    "        if i in fractures:\n",
    "            target = torch.tensor(1)\n",
    "        else:\n",
    "            target = torch.tensor(0)\n",
    "\n",
    "\n",
    "        return img_tensor, target\n",
    "\n",
    "\n",
    "class myDataset_val:\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "\n",
    "        self.data_path = data_path\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(os.listdir(self.data_path))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        img = Image.open(os.path.join(self.data_path, 'img_{}.jpg'.format(i)))\n",
    "\n",
    "        img_array = np.array(img)\n",
    "        img_tensor = torch.tensor(img_array)\n",
    "        img_tensor = torch.unsqueeze(img_tensor, 0)\n",
    "\n",
    "\n",
    "        fractures = [0]\n",
    "\n",
    "        if i in fractures:\n",
    "            target = torch.tensor(1)\n",
    "        else:\n",
    "            target = torch.tensor(0)\n",
    "\n",
    "\n",
    "\n",
    "        return img_tensor, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following cell contains the training loop for the classification with a final check on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thilo/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/home/thilo/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29743240866144854\n",
      "Epoch: 1\n",
      "0.21588283529771227\n",
      "Epoch: 2\n",
      "0.22163926528633704\n",
      "Epoch: 3\n",
      "0.1807943430130503\n",
      "Epoch: 4\n",
      "0.14990449398090797\n",
      "Correct prediction 1\n",
      "Correct prediction 0\n",
      "Wrong. Predicted 0, should have been tensor([1.])\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Wrong. Predicted 0, should have been tensor([1.])\n",
      "Wrong. Predicted 0, should have been tensor([1.])\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 1\n",
      "Wrong. Predicted 0, should have been tensor([1.])\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 1\n",
      "Correct prediction 1\n",
      "Correct prediction 1\n",
      "Correct prediction 0\n",
      "Correct prediction 1\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 1\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 1\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "31 out of 35 train images were correctly classified.\n",
      "Validation Performance:\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Wrong. Predicted 1, should have been tensor([0.])\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Wrong. Predicted 0, should have been tensor([1.])\n",
      "Wrong. Predicted 1, should have been tensor([0.])\n",
      "Wrong. Predicted 1, should have been tensor([0.])\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Wrong. Predicted 1, should have been tensor([0.])\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Wrong. Predicted 1, should have been tensor([0.])\n",
      "Correct prediction 0\n",
      "Wrong. Predicted 1, should have been tensor([0.])\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Wrong. Predicted 1, should have been tensor([0.])\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n",
      "Correct prediction 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# file paths to data set\n",
    "\n",
    "file_path = \"./assets/hand_train\"\n",
    "\n",
    "file_path_val = \"./assets/hand_train\"\n",
    "\n",
    "dataset = myDataset_train(file_path)\n",
    "\n",
    "val_set = myDataset_val(file_path_val)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "dataloader_val = torch.utils.data.DataLoader(val_set, batch_size=1, shuffle=True)\n",
    "\n",
    "images, target = next(iter(dataloader))\n",
    "\n",
    "\n",
    "# call of model architecture\n",
    "model = UNet(n_channels=1, n_classes=2)\n",
    "\n",
    "# select training parameters\n",
    "learning_rate = 1e-5\n",
    "num_epochs = 5\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.999),\n",
    "    )\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "\n",
    "    train_loss_history = []\n",
    "\n",
    "    for image, target in dataloader:\n",
    "\n",
    "        image = image.float()\n",
    "\n",
    "        target = target.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(image)\n",
    "\n",
    "        loss = loss_func(outputs, target)\n",
    "\n",
    "        loss_value = loss.item()\n",
    "\n",
    "        train_loss_history.append(loss_value)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = np.mean(train_loss_history)\n",
    "\n",
    "    loss_history.append(epoch_loss)\n",
    "\n",
    "    print(epoch_loss)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "# analysis of performance on training image after completed training\n",
    "for image, target in dataloader:\n",
    "\n",
    "    total += 1\n",
    "\n",
    "    image = image.float()\n",
    "    target = target.float()\n",
    "    outputs = model(image)\n",
    "\n",
    "    if outputs>0.5:\n",
    "        outputs = 1\n",
    "    else:\n",
    "        outputs = 0\n",
    "\n",
    "    if target == outputs:\n",
    "        correct += 1\n",
    "        print('Correct prediction {}'.format(outputs))\n",
    "    else:\n",
    "        print('Wrong. Predicted {}, should have been {}'.format(outputs, target))\n",
    "\n",
    "print('{} out of {} train images were correctly classified.'.format(correct, total))\n",
    "\n",
    "\n",
    "model_location = \"./assets/models/\" + 'classifier_weights'\n",
    "\n",
    "torch.save(model.state_dict(), model_location)\n",
    "\n",
    "\n",
    "\n",
    "# analysis on validation images to check for successful generalization\n",
    "print('Validation Performance:')\n",
    "for image, target in dataloader_val:\n",
    "\n",
    "    image = image.float()\n",
    "    target = target.float()\n",
    "    outputs = model(image)\n",
    "\n",
    "    if outputs>0.5:\n",
    "        outputs = 1\n",
    "    else:\n",
    "        outputs = 0\n",
    "\n",
    "    if target == outputs:\n",
    "        correct += 1\n",
    "        print('Correct prediction {}'.format(outputs))\n",
    "    else:\n",
    "        print('Wrong. Predicted {}, should have been {}'.format(outputs, target))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c2fea689b1637d52ade41bba95e3b3b8f84163a8415e063cc1cc6f394c4b7e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
